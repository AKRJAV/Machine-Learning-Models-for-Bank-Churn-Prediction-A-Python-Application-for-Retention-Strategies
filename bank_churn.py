# -*- coding: utf-8 -*-
"""22058372_Arjav_Msc_Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r8VpYEMYn7tEq7zmq0FA1Xj6YgF2mr1o
"""

import pandas as pd
data = pd.read_csv('Customer-Churn-Records.csv')
data.head()

data.tail()

data.shape

print("Number of rows: ", data.shape[0])
print("Number of columns: ", data.shape[1])

data.info()

data.describe(include='all').T[['count', 'unique', 'top', 'freq', 'mean', 'std', 'min', 'max']]

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Read the CSV file
data = pd.read_csv('Customer-Churn-Records.csv')
data.drop(columns=['RowNumber', 'CustomerId', 'Surname'], inplace=True)

# Select the numerical columns
numerical_cols = data.select_dtypes(include=['int64', 'float64'])

# Select the nominal (categorical) columns
nominal_cols = data.select_dtypes(include=['object'])

# Function to plot histogram with annotations
def plot_histogram_with_annotations(col_data, col_name, bins=20):
    plt.figure(figsize=(10, 6))
    sns_histplot = sns.histplot(col_data, bins=bins, kde=False, color='skyblue', alpha=0.7)
    plt.title(f'Histogram of {col_name}')
    plt.xlabel(col_name)
    plt.ylabel('Frequency')

    # Annotate histogram
    for p in sns_histplot.patches:
        height = p.get_height()
        if height > 0:  # Add annotation only if height is greater than 0
            sns_histplot.annotate(format(height, '.0f'),
                                  (p.get_x() + p.get_width() / 2., height),
                                  ha='center', va='center',
                                  xytext=(0, 10),
                                  textcoords='offset points',
                                  fontsize=10, color='black', rotation=0)

    # Adjust y-limit to make space for annotations
    max_height = max([p.get_height() for p in sns_histplot.patches])
    plt.ylim(0, max_height * 1.3)  # Adjust to provide more space

    plt.show()

# Plot histogram for numeric data with annotations
for col in numerical_cols.columns:
    if col in ['Age', 'CreditScore']:
        plot_histogram_with_annotations(numerical_cols[col], col, bins=30)  # More bins for detailed data
    else:
        plot_histogram_with_annotations(numerical_cols[col], col)

# Plot bar chart for nominal data with annotations
for col in nominal_cols.columns:
    plt.figure(figsize=(10, 6))
    value_counts = nominal_cols[col].value_counts()
    # Use catplot to handle palettes and avoid warnings
    barplot = sns.catplot(x=value_counts.index, y=value_counts.values, kind='bar', palette="viridis", height=6, aspect=1.5)
    plt.title(f'Bar Chart of {col}')
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=0)

    # Annotate bars with counts
    for ax in barplot.axes.flat:
        for p in ax.patches:
            height = p.get_height()
            if height > 0:  # Add annotation only if height is greater than 0
                ax.annotate(format(height, '.0f'),
                            (p.get_x() + p.get_width() / 2., height),
                            ha='center', va='center',
                            xytext=(0, 10),
                            textcoords='offset points',
                            fontsize=10, color='black', rotation=0)

    plt.tight_layout()
    plt.show()

data = pd.get_dummies(data)
data

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

numeric_df = data.select_dtypes(include=['int64', 'float64', 'bool'])

# Compute the correlation matrix
corr_matrix = numeric_df.corr()

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm',vmin=-1,vmax=1)
plt.title('Correlation Matrix for Numeric Features')
plt.show()

exited = data['Exited'].value_counts()
exited

import matplotlib.pyplot as plt

total_customers = exited.sum()  # Total number of customers
labels_with_counts = [f'Not Exited ({exited[0]})', f'Exited ({exited[1]})']

plt.figure(figsize=(6, 4))
plt.pie(exited, labels=['Not Exited (0)', 'Exited (1)'], autopct='%1.2f%%', startangle=360)
plt.axis('equal')

plt.title(f'Churn Overview of {total_customers} Customers')

plt.legend(labels_with_counts, title="Customers", loc='upper left', bbox_to_anchor=(1, 1))
plt.tight_layout()
plt.show()

X = data.drop(columns=['Exited','Complain'])
y = data['Exited']

X.info()

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)

print("Training Data Size: ", X_train.shape, y_train.shape)
print("Testing Data Size: ", X_test.shape,y_test.shape)
print("")
print("Target Column Before SMOTE")
print("------------------------------------------")
print(y_train.value_counts())

from imblearn.over_sampling import SMOTE
X_train_resample, y_train_resample = SMOTE(random_state=50).fit_resample(X_train, y_train)

print("Target Column After SMOTE")
print("--------------------------------------")
print(y_train_resample.value_counts())

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import BernoulliNB

svm = SVC(random_state=50)
lr = LogisticRegression(random_state=50)
knn = KNeighborsClassifier()
gb = GradientBoostingClassifier(random_state=50)
rf = RandomForestClassifier(random_state=50)
dt = DecisionTreeClassifier(random_state=50)
nb = BernoulliNB()

lr.fit(X_train_resample, y_train_resample)
svm.fit(X_train_resample, y_train_resample)
knn.fit(X_train_resample, y_train_resample)
gb.fit(X_train_resample, y_train_resample)
rf.fit(X_train_resample, y_train_resample)
dt.fit(X_train_resample, y_train_resample)
nb.fit(X_train_resample, y_train_resample)

y_pred1 = lr.predict(X_test)
y_pred2 = svm.predict(X_test)
y_pred3 = knn.predict(X_test)
y_pred4 = gb.predict(X_test)
y_pred5 = rf.predict(X_test)
y_pred6 = dt.predict(X_test)
y_pred7 = nb.predict(X_test)

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Accuracy scores
accuracies = [
    round(accuracy_score(y_test, y_pred1), 2),
    round(accuracy_score(y_test, y_pred2), 2),
    round(accuracy_score(y_test, y_pred3), 2),
    round(accuracy_score(y_test, y_pred4), 2),
    round(accuracy_score(y_test, y_pred5), 2),
    round(accuracy_score(y_test, y_pred6), 2),
    round(accuracy_score(y_test, y_pred7), 2)
]

models = ['Logistic R', 'SVC', 'KNN', 'G-Boosting', 'Random-F', 'Decision-Tree', 'BernoulliNB']

# Accuracy Bar Plot
plt.figure(figsize=(10, 6))
plt.bar(models, accuracies, color=['red', 'blue', 'green', 'purple', 'orange', 'cyan', 'magenta'])
plt.title('Model Accuracy Comparison')
plt.xlabel('Classification Models')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
for i, v in enumerate(accuracies):
    plt.text(i, v + 0.01, str(v), ha='center')

plt.show()

# Precision scores
precisions = [
    round(precision_score(y_test, y_pred1), 2),
    round(precision_score(y_test, y_pred2), 2),
    round(precision_score(y_test, y_pred3), 2),
    round(precision_score(y_test, y_pred4), 2),
    round(precision_score(y_test, y_pred5), 2),
    round(precision_score(y_test, y_pred6), 2),
    round(precision_score(y_test, y_pred7), 2)
]

# Precision Bar Plot
plt.figure(figsize=(10, 6))
plt.bar(models, precisions, color=['red', 'blue', 'green', 'purple', 'orange', 'cyan', 'magenta'])
plt.title('Model Precision Comparison')
plt.xlabel('Classification Models')
plt.ylabel('Precision')
plt.ylim(0, 1)
for i, v in enumerate(precisions):
    plt.text(i, v + 0.01, str(v), ha='center')
plt.show()

# Recall scores
recalls = [
    round(recall_score(y_test, y_pred1), 2),
    round(recall_score(y_test, y_pred2), 2),
    round(recall_score(y_test, y_pred3), 2),
    round(recall_score(y_test, y_pred4), 2),
    round(recall_score(y_test, y_pred5), 2),
    round(recall_score(y_test, y_pred6), 2),
    round(recall_score(y_test, y_pred7), 2)
]

# Recall Bar Plot
plt.figure(figsize=(10, 6))
plt.bar(models, recalls, color=['red', 'blue', 'green', 'purple', 'orange', 'cyan', 'magenta'])
plt.title('Model Recall Comparison')
plt.xlabel('Classification Models')
plt.ylabel('Recall')
plt.ylim(0, 1)
for i, v in enumerate(recalls):
    plt.text(i, v + 0.01, str(v), ha='center')
plt.show()

# F1 scores
f1_scores = [
    round(f1_score(y_test, y_pred1), 2),
    round(f1_score(y_test, y_pred2), 2),
    round(f1_score(y_test, y_pred3), 2),
    round(f1_score(y_test, y_pred4), 2),
    round(f1_score(y_test, y_pred5), 2),
    round(f1_score(y_test, y_pred6), 2),
    round(f1_score(y_test, y_pred7), 2)
]

# F1-Score Bar Plot
plt.figure(figsize=(10, 6))
plt.bar(models, f1_scores, color=['red', 'blue', 'green', 'purple', 'orange', 'cyan', 'magenta'])
plt.title('Model F1-Score Comparison')
plt.xlabel('Classification Models')
plt.ylabel('F1-Score')
plt.ylim(0, 1)
for i, v in enumerate(f1_scores):
    plt.text(i, v + 0.01, str(v), ha='center')
plt.show()

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_curve, auc
from sklearn.naive_bayes import BernoulliNB
import matplotlib.pyplot as plt

# Initialize the models
models = {
    'SVC': SVC(probability=True, random_state=50),
    'Logistic Regression': LogisticRegression(random_state=50),
    'Random Forest': RandomForestClassifier(random_state=50),
    'Decision Tree': DecisionTreeClassifier(random_state=50),
    'Gradient Boosting': GradientBoostingClassifier(random_state=50),
    'KNN': KNeighborsClassifier(),
    'Bernoulli NB' : BernoulliNB()
}

# Fit the models and predict probabilities
probas = {}
for model_name, model in models.items():
    model.fit(X_train_resample, y_train_resample)
    probas[model_name] = model.predict_proba(X_test)[:, 1]

# Plot ROC curves
#plt.figure(figsize=(9, 7))

for model_name, y_proba in probas.items():
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'{model_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve of Different Classification Models')
plt.legend(loc="lower right")
plt.tight_layout()
plt.show()

import numpy as np
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# Initialize the models
models = {
    'SVC': SVC(probability=True, random_state=50),
    'Logistic Regression': LogisticRegression(random_state=50),
    'Random Forest': RandomForestClassifier(random_state=50),
    'Decision Tree': DecisionTreeClassifier(random_state=50),
    'Gradient Boosting': GradientBoostingClassifier(random_state=50),
    'KNN': KNeighborsClassifier(),
    'Bernoulli NB': BernoulliNB()
}

# Store evaluation metrics
metrics = {
    'Model': [],
    'Accuracy': [],
    'Precision': [],
    'Recall': [],
    'F1-Score': [],
    'AUC-ROC': []
}

# Fit models and calculate metrics
for model_name, model in models.items():
    model.fit(X_train_resample, y_train_resample)
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    metrics['Model'].append(model_name)
    metrics['Accuracy'].append(round(accuracy_score(y_test, y_pred), 2))
    metrics['Precision'].append(round(precision_score(y_test, y_pred), 2))
    metrics['Recall'].append(round(recall_score(y_test, y_pred), 2))
    metrics['F1-Score'].append(round(f1_score(y_test, y_pred), 2))
    metrics['AUC-ROC'].append(round(roc_auc_score(y_test, y_proba), 2))

# Create a DataFrame
metrics_df = pd.DataFrame(metrics)

# Display the DataFrame
metrics_df

gb

import joblib
joblib.dump(gb, 'churn_model_prediction')
model = joblib.load('churn_model_prediction')

###### Bank Churn Prediction Code ################
import joblib
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler
import io
import logging
import matplotlib.pyplot as plt
import seaborn as sns
from openpyxl import load_workbook
from openpyxl.styles import Border, Side
import openpyxl
from openpyxl.drawing.image import Image
from openpyxl.utils import get_column_letter
from IPython.display import HTML, display

# Initialize logging
logging.basicConfig(filename='application.log', level=logging.INFO, format='%(asctime)s %(message)s')

# Load the model
model = joblib.load('churn_model_prediction')

# Create a new StandardScaler
sc = StandardScaler()

# Define the feature ranges based on your original dataset
feature_ranges = {
    'CreditScore': (300, 850),
    'Age': (18, 100),
    'Tenure': (0, 10),
    'Balance': (0, 250000),
    'NumOfProducts': (1, 4),
    'EstimatedSalary': (0, 200000),
    'Satisfaction Score': (1, 5),
    'Point Earned': (100, 1000)
}

dummy_data = np.array([
    [feature_ranges[f][1] for f in ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary', 'Satisfaction Score', 'Point Earned']] +
    [1, 1] +  # HasCrCard, IsActiveMember
    [1, 0, 0] +  # Germany, Spain, France
    [1, 0] +  # Male, Female
    [1, 0, 0, 0]  # SILVER, GOLD, DIAMOND, PLATINUM
])

# Fit the scaler on the dummy data
sc.fit(dummy_data)

def predict_churn_probability(row):
    geography_map = {'Germany': [1, 0, 0], 'Spain': [0, 1, 0], 'France': [0, 0, 1]}
    geography_encoded = geography_map[row['Geography']]
    gender_male = 1 if row['Gender'] == 'Male' else 0
    gender_female = 1 if row['Gender'] == 'Female' else 0
    card_type_map = {'SILVER': [1, 0, 0, 0], 'GOLD': [0, 1, 0, 0], 'DIAMOND': [0, 0, 1, 0], 'PLATINUM': [0, 0, 0, 1]}
    card_type_encoded = card_type_map.get(row['Card Type'], [0, 0, 0, 0])

    input_data = [row['CreditScore'], row['Age'], row['Tenure'], row['Balance'], row['NumOfProducts'], row['HasCrCard'], row['IsActiveMember'], row['EstimatedSalary'], row['Satisfaction Score'], row['Point Earned']] + \
                 geography_encoded + [gender_male, gender_female] + card_type_encoded

    input_data_scaled = sc.transform([input_data])
    churn_probability = model.predict_proba(input_data_scaled)[0][1]  # Probability of class 1 (churn)
    return churn_probability

def determine_risk_level(probability):
    if probability <= 0.25:
        return "LOW"
    elif 0.26 <= probability <= 0.50:
        return "MEDIUM"
    elif 0.51 <= probability <= 0.75:
        return "HIGH"
    else:
        return "VERY HIGH"

def process_excel(file_content):
    df = pd.read_csv(io.BytesIO(file_content))
    df['ChurnProbability'] = df.apply(predict_churn_probability, axis=1)
    df['RiskLevel'] = df['ChurnProbability'].apply(lambda x: determine_risk_level(x))

    total_customers = df.shape[0]
    risk_counts = df['RiskLevel'].value_counts().to_dict()
    avg_churn_prob = df['ChurnProbability'].mean()
    max_churn_prob = df['ChurnProbability'].max()
    min_churn_prob = df['ChurnProbability'].min()
    highest_risk_level = max(risk_counts, key=risk_counts.get)

    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 30, 45, 60, 100], labels=['18-30', '31-45', '46-60', '60+'])
    df['TenureGroup'] = pd.cut(df['Tenure'], bins=[-1, 2, 5, 8, 10], labels=['0-2', '3-5', '6-8', '9-10'])
    df['SalaryRange'] = pd.cut(df['EstimatedSalary'], bins=[0, 50000, 100000, 150000, float('inf')], labels=['0-50k', '50k-100k', '100k-150k', '150k+'])
    df['SatisfactionRange'] = pd.cut(df['Satisfaction Score'], bins=[0, 2, 3, 4, 5], labels=['1-2', '2-3', '3-4', '4-5'])
    df['PointsRange'] = pd.cut(df['Point Earned'], bins=[0, 250, 500, 750, 1000], labels=['0-250', '251-500', '501-750', '751-1000'])
    df['CreditScoreRange'] = pd.cut(df['CreditScore'], bins=[300, 500, 600, 700, 850], labels=['300-500', '501-600', '601-700', '701-850'])
    df['BalanceRange'] = pd.cut(df['Balance'], bins=[-1, 0, 1000, 50000, 100000, 150000, 200000, float('inf')], labels=['0', '1-1000', '1k-50k', '50k-100k', '100k-150k', '150k-200k', '200k+'])

    summary_stats = {
        'Metric': ['Total Customers', 'Low Risk', 'Medium Risk', 'High Risk', 'Very High Risk', 'Average Churn Probability', 'Maximum Churn Probability', 'Minimum Churn Probability', 'Highest Risk Level'],
        'Value': [total_customers, risk_counts.get('LOW', 0), risk_counts.get('MEDIUM', 0), risk_counts.get('HIGH', 0), risk_counts.get('VERY HIGH', 0), f"{avg_churn_prob:.2%}", f"{max_churn_prob:.2%}", f"{min_churn_prob:.2%}", highest_risk_level]
    }

    return df, pd.DataFrame(summary_stats)

def plot_risk_level_bar_chart(df):
    risk_level_order = ['LOW', 'MEDIUM', 'HIGH', 'VERY HIGH']
    risk_counts = df['RiskLevel'].value_counts().reindex(risk_level_order).fillna(0)
    total_customers = df.shape[0]

    plt.figure(figsize=(12, 8))
    ax = sns.barplot(x=risk_counts.index, y=risk_counts.values, palette='Set2', order=risk_level_order)

    for p in ax.patches:
        height = p.get_height()
        ax.annotate(f'{int(height)}', (p.get_x() + p.get_width() / 2., height),
                    ha='center', va='bottom', fontsize=12, color='black', xytext=(0, 5),
                    textcoords='offset points')

    handles = []
    colors = sns.color_palette('Set2', n_colors=len(risk_level_order))
    for i, risk_level in enumerate(risk_level_order):
        handles.append(plt.Rectangle((0, 0), 1, 1, color=colors[i]))
    labels = [f'{risk_level} ({int(risk_counts[risk_level])})' for risk_level in risk_level_order]
    ax.legend(handles, labels, title='Risk Level Counts', loc='upper right', fontsize=12)

    plt.title(f'Distribution of Risk Levels (Total Customers: {total_customers})', fontsize=20)
    plt.xlabel('Risk Level', fontsize=16)
    plt.ylabel('Number of Customers', fontsize=16)
    plt.xticks(rotation=0, fontsize=14)
    plt.yticks(fontsize=14)
    plt.tight_layout()
    return plt.gcf()

def plot_grouped_bar_chart(df, feature_name):
    feature_counts = df.groupby(['RiskLevel', feature_name]).size().unstack(fill_value=0)

    # Remove columns and rows with all zeros
    feature_counts = feature_counts.loc[:, (feature_counts != 0).any(axis=0)]
    feature_counts = feature_counts.loc[(feature_counts != 0).any(axis=1)]

    # Sort columns by the maximum count
    feature_counts = feature_counts.reindex(columns=feature_counts.max().sort_values(ascending=False).index)

    # Ensure correct order of risk levels
    risk_level_order = ['LOW', 'MEDIUM', 'HIGH', 'VERY HIGH']
    feature_counts = feature_counts.reindex(risk_level_order)

    plt.figure(figsize=(20, 10))
    ax = feature_counts.plot(kind='bar', width=0.8, figsize=(20, 10))

    plt.title(f'Contribution of {feature_name} by Risk Level', fontsize=24)
    plt.xlabel('Risk Level', fontsize=18)
    plt.ylabel('Number of Customers', fontsize=18)
    plt.xticks(rotation=0, fontsize=16)
    plt.yticks(fontsize=16)
    plt.legend(title=feature_name, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=14, title_fontsize=16)

    # Add value labels on top of each bar, excluding 0 values
    for container in ax.containers:
        ax.bar_label(container, label_type='edge', fontsize=15, padding=2,
                     labels=[f'{int(v.get_height())}' if v.get_height() > 0 else '' for v in container])

    plt.tight_layout()
    return plt.gcf()

def plot_churn_probability_distribution(df):
    plt.figure(figsize=(15, 9))
    sns.histplot(df['ChurnProbability'], kde=False, color='skyblue', bins=30)
    plt.title('Distribution of Churn Probability', fontsize=24)
    plt.xlabel('Churn Probability', fontsize=18)
    plt.ylabel('Frequency', fontsize=18)
    plt.xticks(fontsize=14)
    plt.yticks(fontsize=14)
    plt.tight_layout()
    return plt.gcf()

def visualize_results(df):
    categorical_features = ['Geography', 'Gender', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'Card Type']
    range_features = ['AgeGroup', 'TenureGroup', 'SalaryRange', 'SatisfactionRange', 'PointsRange', 'CreditScoreRange', 'BalanceRange']
    all_features = categorical_features + range_features
    plots = {}

    plots['Risk Level Distribution'] = plot_risk_level_bar_chart(df)
    plt.show()

    plots['Churn Probability Distribution'] = plot_churn_probability_distribution(df)
    plt.show()

    for feature in all_features:
        plots[f'{feature} Distribution'] = plot_grouped_bar_chart(df, feature)
        plt.show()

    return plots

def file_input():
    print("\n-----------------------------------------------------------------------------")
    print("Upload CSV Data With Following Columns....")
    print("-----------------------------------------------------------------------------\n")
    print("CustomerId, Surname, CreditScore, Geography, Gender, Age, Tenure, Balance, \nNumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary, Satisfaction Score, Card Type, Point Earned")
    print("-----------------------------------------------------------------------------\n")
    file_path = input("Enter the path to your CSV file: ")

    try:
        with open(file_path, 'rb') as file:
            file_content = file.read()

        result_df, summary_stats_df = process_excel(file_content)

        display(HTML(result_df.to_html(index=False, classes='table table-striped')))
        display(HTML(summary_stats_df.to_html(index=False, classes='table table-striped')))

        plots = visualize_results(result_df)

        save_option = input("Do you want to save the results, summary, and plots as an Excel file? (yes/no): ").lower()
        if save_option == 'yes':
            output_path = input("Enter the path for the output Excel file: ")
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                result_df.to_excel(writer, sheet_name='Processed Data', index=False)
                summary_stats_df.to_excel(writer, sheet_name='Summary', index=False)

                for plot_name, fig in plots.items():
                    worksheet = writer.book.create_sheet(title=plot_name)
                    imgdata = io.BytesIO()
                    fig.savefig(imgdata, format='png', dpi=300, bbox_inches='tight')
                    img = openpyxl.drawing.image.Image(imgdata)
                    img.width = 800
                    img.height = 600
                    worksheet.add_image(img, 'B2')

                    for col in range(1, 15):
                        column_letter = get_column_letter(col)
                        worksheet.column_dimensions[column_letter].width = 20
                    for row in range(1, 30):
                        worksheet.row_dimensions[row].height = 25

            wb = load_workbook(output_path)
            ws = wb['Summary']
            thin_border = Border(left=Side(style='thin'),
                                 right=Side(style='thin'),
                                 top=Side(style='thin'),
                                 bottom=Side(style='thin'))
            for row in ws.iter_rows():
                for cell in row:
                    cell.border = thin_border
            wb.save(output_path)

            print(f"Results, summary, and plots saved to {output_path}")

    except Exception as e:
        logging.error(f"Error while processing file: {str(e)}")
        print(f"An error occurred: {str(e)}")

def main():
    while True:
        print()
        print("_____________________________________")
        print("\nBank Churn Prediction Application")
        print("_____________________________________")
        print("")
        print("1. Upload and Process CSV File")
        print("2. Exit")
        print("")
        choice = input("Enter your choice (1 / 2): ")
        if choice == '1':
            file_input()
            print("Exiting the application. Goodbye!")
            break
        elif choice == '3':
            print("Invalid choice. Please try again.")
            break
        else:
            print("Invalid choice. Please try again.")

if __name__ == "__main__":
    main()